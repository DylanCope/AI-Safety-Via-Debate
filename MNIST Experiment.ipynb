{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Safety via Debate: MNIST Experiment\n",
    "\n",
    "In the [original paper](https://arxiv.org/abs/1805.00899) on debate, the authors describe a simple experiment that they performed:\n",
    "\n",
    "> Metaphorically, debate targets the situation where the agents see the big picture, but the judge cannot. We can model this by replacing the metaphorical big picture with an actual picture, chosen at random from a distribution. If the image is simple enough, we can do away with natural language entirely: the two agents state their claimed image class up front, then reveal one pixel of the image per turn to the judge. They cannot lie about these pixels, but a dishonest player could choose them adversarially to fool the judge. The game ends after a fixed number of turns, then the judge sees a sparse mask of the revealed pixels and decides which agentâ€™s class is correct.\n",
    "\n",
    "<img src=\"https://openai.com/content/images/2018/05/debate-game-flow-figure@2x.png\"/>\n",
    "\n",
    "To start with, we will create the weak-classifier judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import random\n",
    "from itertools import cycle\n",
    "\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalise(x: np.ndarray) -> np.ndarray:\n",
    "    x = x - np.min(x)\n",
    "    x = x / np.max(x)\n",
    "    return x\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    '''\n",
    "        DataGenerator adapted from \n",
    "        https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data: np.ndarray or List[np.ndarray], \n",
    "                 labels: np.ndarray, \n",
    "                 batch_size=32, \n",
    "                 dim=(28, 28), \n",
    "                 n_channels=1,\n",
    "                 n_classes=10, \n",
    "                 shuffle=True, \n",
    "                 seed=None):\n",
    "        'Initialization'\n",
    "        \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.labels = to_categorical(labels, \n",
    "                                     num_classes=self.n_classes)\n",
    "        self.data = np.array([\n",
    "                normalise(sample) \n",
    "                for sample in data\n",
    "        ])\n",
    "        \n",
    "        num_samples, *_ = self.data.shape\n",
    "        self.indices = np.arange(num_samples)\n",
    "        self.idx_iterator = cycle(range(0, len(self)))\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indices after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.indices.size / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        i = index*self.batch_size\n",
    "        j = (index + 1)*self.batch_size\n",
    "        indices = self.indices[i:j]\n",
    "\n",
    "        # Generate data\n",
    "        X = self.data[indices]\n",
    "        y = self.labels[indices]\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self[next(self.idx_iterator)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MaskedDataGenerator(DataGenerator):\n",
    "    '''\n",
    "        DataGenerator that randomly masks generated samples such that only\n",
    "        a few non-zero elements are preserved.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 data: np.ndarray or List[np.ndarray], \n",
    "                 labels: np.ndarray, \n",
    "                 num_preserved=5, \n",
    "                 **kwargs):\n",
    "        super(MaskedDataGenerator, self).__init__(data, labels, **kwargs)\n",
    "        self.num_preserved = num_preserved\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_mask(img: np.ndarray, \n",
    "                     num_preserved: int) -> np.ndarray:\n",
    "        non_zero_elements = np.argwhere(img)\n",
    "        num_non_zero, *_ = non_zero_elements.shape\n",
    "        sample_indices = np.random.choice(np.arange(num_non_zero), \n",
    "                                          size=num_preserved)\n",
    "        sample = non_zero_elements[sample_indices]\n",
    "        mask = np.zeros(img.shape)\n",
    "        mask[sample[:, 0], sample[:, 1]] = 1\n",
    "        return mask\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        X, y = super(MaskedDataGenerator, self).__getitem__(index)\n",
    "        masks = np.array([\n",
    "                self._create_mask(img, self.num_preserved)\n",
    "                for img in X\n",
    "        ])\n",
    "        return X*masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sampling of the generated data is shown below with the original images in light blue and the brighter pixels showing what is revealled after the masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(10, 4))\n",
    "mnist_train_data_gen = DataGenerator(X_train, y_train, seed=0)\n",
    "for row in axs:\n",
    "    for ax in row:\n",
    "        (img, *_), y = next(mnist_train_data_gen)\n",
    "        mask = MaskedDataGenerator._create_mask(img, 5)\n",
    "        ax.imshow(img*0.5 + mask)\n",
    "        ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Judge Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 600,810\n",
      "Trainable params: 600,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def judge_untrained():\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "    output = Convolution2D(32, (3, 3), activation='relu')(inputs)\n",
    "    output = Convolution2D(32, (3, 3), activation='relu')(output)\n",
    "    output = MaxPooling2D(pool_size=(2,2))(output)\n",
    "    output = Dropout(0.25)(output)\n",
    "\n",
    "    output = Flatten()(output)\n",
    "    output = Dense(128, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(10, activation='softmax')(output)\n",
    "    \n",
    "    model = keras.Model(inputs=[inputs], outputs=[output])   \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "judge_untrained().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Judge\n",
    "\n",
    "Firstly, we will do a sanity check and train a judge on unmasked data to verify that it learns to perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1875/1875 [==============================] - 61s 33ms/step - loss: 0.2097 - acc: 0.9354 - val_loss: 0.0548 - val_acc: 0.9827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228e3bc5d68>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge = judge_untrained()\n",
    "train_data_gen = DataGenerator(X_train.reshape(X_train.shape + (1,)), \n",
    "                               y_train, seed=0)\n",
    "val_data_gen = DataGenerator(X_test.reshape(X_test.shape + (1,)), \n",
    "                             y_test)\n",
    "judge.fit_generator(train_data_gen, validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it achieves an accuracy score of 98.3% on the test data.\n",
    "\n",
    "Now, when we train it on the masked data (only 5 pixels shown), we can see that it performs significantly worse with a test accuracy of 46.9%. A number that is comparable to the results in the paper (section 3, table 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 1.6854 - acc: 0.4054 - val_loss: 1.4945 - val_acc: 0.4688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228e3dc0048>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge = judge_untrained()\n",
    "train_data_gen = MaskedDataGenerator(X_train.reshape(X_train.shape + (1,)), \n",
    "                                     y_train, seed=0)\n",
    "val_data_gen = MaskedDataGenerator(X_test.reshape(X_test.shape + (1,)), \n",
    "                                   y_test)\n",
    "judge.fit_generator(train_data_gen, validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
